{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOigmEDaS0APwBPUv3l4MpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yamachanyama/AI_Statistics/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxwEa40mhAz"
      },
      "outputs": [],
      "source": [
        "# classification1_perceptron　～パーセプトロンの実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/images1.csv', delimiter=',', skiprows=1)\n",
        "train_x = train[:,0:2]\n",
        "train_y = train[:,2]\n",
        "\n",
        "# 重みの初期化\n",
        "w = np.random.rand(2)\n",
        "\n",
        "# 識別関数\n",
        "def f(x):\n",
        "    if np.dot(w, x) >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# 繰り返し回数\n",
        "epoch = 10\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 重みを学習する\n",
        "for _ in range(epoch):\n",
        "    for x, y in zip(train_x, train_y):\n",
        "        if f(x) != y:\n",
        "            w = w + y * x\n",
        "\n",
        "            # ログの出力\n",
        "            count += 1\n",
        "            print('{}回目: w = {}'.format(count, w))\n",
        "\n",
        "# プロットして確認\n",
        "x1 = np.arange(0, 500)\n",
        "plt.plot(train_x[train_y ==  1, 0], train_x[train_y ==  1, 1], 'o')\n",
        "plt.plot(train_x[train_y == -1, 0], train_x[train_y == -1, 1], 'x')\n",
        "plt.plot(x1, -w[0] / w[1] * x1, linestyle='dashed')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classification2_logistic_regression　～ロジスティックス回帰の実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/images2.csv', delimiter=',', skiprows=1)\n",
        "train_x = train[:,0:2]\n",
        "train_y = train[:,2]\n",
        "\n",
        "# パラメータを初期化\n",
        "theta = np.random.rand(3)\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean(axis=0)\n",
        "sigma = train_x.std(axis=0)\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# x0を加える\n",
        "def to_matrix(x):\n",
        "    x0 = np.ones([x.shape[0], 1])\n",
        "    return np.hstack([x0, x])\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# シグモイド関数\n",
        "def f(x):\n",
        "    return 1 / (1 + np.exp(-np.dot(x, theta)))\n",
        "\n",
        "# 分類関数\n",
        "def classify(x):\n",
        "    return (f(x) >= 0.5).astype(np.int)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 繰り返し回数\n",
        "epoch = 5000\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 学習を繰り返す\n",
        "for _ in range(epoch):\n",
        "    theta = theta - ETA * np.dot(f(X) - train_y, X)\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    print('{}回目: theta = {}'.format(count, theta))\n",
        "\n",
        "# プロットして確認\n",
        "x0 = np.linspace(-2, 2, 100)\n",
        "plt.plot(train_z[train_y == 1, 0], train_z[train_y == 1, 1], 'o')\n",
        "plt.plot(train_z[train_y == 0, 0], train_z[train_y == 0, 1], 'x')\n",
        "plt.plot(x0, -(theta[0] + theta[1] * x0) / theta[2], linestyle='dashed')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QBh_0AR5sBS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification3_logistic_polynomial_regression　～線形分離不可能な分類を実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/data3.csv', delimiter=',', skiprows=1)\n",
        "train_x = train[:,0:2]\n",
        "train_y = train[:,2]\n",
        "\n",
        "# パラメータを初期化\n",
        "theta = np.random.rand(4)\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean(axis=0)\n",
        "sigma = train_x.std(axis=0)\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# x0とx3を加える\n",
        "def to_matrix(x):\n",
        "    x0 = np.ones([x.shape[0], 1])\n",
        "    x3 = x[:,0,np.newaxis] ** 2\n",
        "    return np.hstack([x0, x, x3])\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# シグモイド関数\n",
        "def f(x):\n",
        "    return 1 / (1 + np.exp(-np.dot(x, theta)))\n",
        "\n",
        "# 分類関数\n",
        "def classify(x):\n",
        "    return (f(x) >= 0.5).astype(np.int)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 繰り返し回数\n",
        "epoch = 5000\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 学習を繰り返す\n",
        "for _ in range(epoch):\n",
        "    theta = theta - ETA * np.dot(f(X) - train_y, X)\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    print('{}回目: theta = {}'.format(count, theta))\n",
        "\n",
        "# プロットして確認\n",
        "x1 = np.linspace(-2, 2, 100)\n",
        "x2 = -(theta[0] + theta[1] * x1 + theta[3] * x1 ** 2) / theta[2]\n",
        "plt.plot(train_z[train_y == 1, 0], train_z[train_y == 1, 1], 'o')\n",
        "plt.plot(train_z[train_y == 0, 0], train_z[train_y == 0, 1], 'x')\n",
        "plt.plot(x1, x2, linestyle='dashed')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h9Rm21iIsNWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification4_logistic_regression_sgd　～確率的勾配降下法の実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/data3.csv', delimiter=',', skiprows=1)\n",
        "train_x = train[:,0:2]\n",
        "train_y = train[:,2]\n",
        "\n",
        "# パラメータを初期化\n",
        "theta = np.random.rand(4)\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean(axis=0)\n",
        "sigma = train_x.std(axis=0)\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# x0とx3を加える\n",
        "def to_matrix(x):\n",
        "    x0 = np.ones([x.shape[0], 1])\n",
        "    x3 = x[:,0,np.newaxis] ** 2\n",
        "    return np.hstack([x0, x, x3])\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# シグモイド関数\n",
        "def f(x):\n",
        "    return 1 / (1 + np.exp(-np.dot(x, theta)))\n",
        "\n",
        "# 分類関数\n",
        "def classify(x):\n",
        "    return (f(x) >= 0.5).astype(np.int)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 繰り返し回数\n",
        "epoch = 5000\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 学習を繰り返す\n",
        "for _ in range(epoch):\n",
        "    # 確率的勾配降下法でパラメータ更新\n",
        "    p = np.random.permutation(X.shape[0])\n",
        "    for x, y in zip(X[p,:], train_y[p]):\n",
        "        theta = theta - ETA * (f(x) - y) * x\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    print('{}回目: theta = {}'.format(count, theta))\n",
        "\n",
        "# プロットして確認\n",
        "x1 = np.linspace(-2, 2, 100)\n",
        "x2 = -(theta[0] + theta[1] * x1 + theta[3] * x1 ** 2) / theta[2]\n",
        "plt.plot(train_z[train_y == 1, 0], train_z[train_y == 1, 1], 'o')\n",
        "plt.plot(train_z[train_y == 0, 0], train_z[train_y == 0, 1], 'x')\n",
        "plt.plot(x1, x2, linestyle='dashed')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mMa3iKcXtExx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression1_linear ～１次関数として実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/click.csv', delimiter=',', dtype='int', skiprows=1)\n",
        "train_x = train[:,0]\n",
        "train_y = train[:,1]\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean()\n",
        "sigma = train_x.std()\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# パラメータを初期化\n",
        "theta0 = np.random.rand()\n",
        "theta1 = np.random.rand()\n",
        "\n",
        "# 予測関数\n",
        "def f(x):\n",
        "    return theta0 + theta1 * x\n",
        "\n",
        "# 目的関数\n",
        "def E(x, y):\n",
        "    return 0.5 * np.sum((y - f(x)) ** 2)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 誤差の差分\n",
        "diff = 1\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 誤差の差分が0.01以下になるまでパラメータ更新を繰り返す\n",
        "error = E(train_z, train_y)\n",
        "while diff > 1e-2:\n",
        "    # 更新結果を一時変数に保存\n",
        "    tmp_theta0 = theta0 - ETA * np.sum((f(train_z) - train_y))\n",
        "    tmp_theta1 = theta1 - ETA * np.sum((f(train_z) - train_y) * train_z)\n",
        "\n",
        "    # パラメータを更新\n",
        "    theta0 = tmp_theta0\n",
        "    theta1 = tmp_theta1\n",
        "\n",
        "    # 前回の誤差との差分を計算\n",
        "    current_error = E(train_z, train_y)\n",
        "    diff = error - current_error\n",
        "    error = current_error\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    log = '{}回目: theta0 = {:.3f}, theta1 = {:.3f}, 差分 = {:.4f}'\n",
        "    print(log.format(count, theta0, theta1, diff))\n",
        "\n",
        "# プロットして確認\n",
        "x = np.linspace(-3, 3, 100) #https://note.nkmk.me/python-numpy-arange-linspace/\n",
        "plt.plot(train_z, train_y, 'o')\n",
        "plt.plot(x, f(x))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MrRMmfl_tYf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression2_polynomial　～多項式回帰の実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/click.csv', delimiter=',', dtype='int', skiprows=1)\n",
        "train_x = train[:,0]\n",
        "train_y = train[:,1]\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean()\n",
        "sigma = train_x.std()\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# パラメータを初期化\n",
        "theta = np.random.rand(3)\n",
        "\n",
        "# 学習データの行列を作る\n",
        "def to_matrix(x):\n",
        "#    return np.vstack([np.ones(x.size), x, x ** 2]).T\n",
        "     return np.vstack([np.ones(x.shape[0]), x, x ** 2]).T\n",
        "\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# 予測関数\n",
        "def f(x):\n",
        "    return np.dot(x, theta)\n",
        "\n",
        "# 目的関数\n",
        "def E(x, y):\n",
        "    return 0.5 * np.sum((y - f(x)) ** 2)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 誤差の差分\n",
        "diff = 1\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 誤差の差分が0.01以下になるまでパラメータ更新を繰り返す\n",
        "error = E(X, train_y)\n",
        "while diff > 1e-2:\n",
        "    # 更新結果を一時変数に保存\n",
        "    theta = theta - ETA * np.dot(f(X) - train_y, X)\n",
        "\n",
        "    # 前回の誤差との差分を計算\n",
        "    current_error = E(X, train_y)\n",
        "    diff = error - current_error\n",
        "    error = current_error\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    log = '{}回目: theta = {}, 差分 = {:.4f}'\n",
        "    print(log.format(count, theta, diff))\n",
        "\n",
        "# プロットして確認\n",
        "x = np.linspace(-3, 3, 100)\n",
        "plt.plot(train_z, train_y, 'o')\n",
        "plt.plot(x, f(to_matrix(x)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B52y4qFate6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression3_sgd　～確率的勾配降下法の実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習データを読み込む\n",
        "train = np.loadtxt('https://raw.githubusercontent.com/yamachanyama/AI_Statistics/main/click.csv', delimiter=',', dtype='int', skiprows=1)\n",
        "train_x = train[:,0]\n",
        "train_y = train[:,1]\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean()\n",
        "sigma = train_x.std()\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# パラメータを初期化\n",
        "theta = np.random.rand(3)\n",
        "\n",
        "# 学習データの行列を作る\n",
        "def to_matrix(x):\n",
        "    return np.vstack([np.ones(x.size), x, x ** 2]).T\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# 予測関数\n",
        "def f(x):\n",
        "    return np.dot(x, theta)\n",
        "\n",
        "# 平均二乗誤差\n",
        "def MSE(x, y):\n",
        "    return (1 / x.shape[0]) * np.sum((y - f(x)) ** 2)\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-3\n",
        "\n",
        "# 誤差の差分\n",
        "diff = 1\n",
        "\n",
        "# 更新回数\n",
        "count = 0\n",
        "\n",
        "# 学習を繰り返す\n",
        "error = MSE(X, train_y)\n",
        "while diff > 1e-2:\n",
        "    # 確率的勾配降下法でパラメータ更新\n",
        "    p = np.random.permutation(X.shape[0])\n",
        "    for x, y in zip(X[p,:], train_y[p]):\n",
        "        theta = theta - ETA * (f(x) - y) * x\n",
        "\n",
        "    # 前回の誤差との差分を計算\n",
        "    current_error = MSE(X, train_y)\n",
        "    diff = error - current_error\n",
        "    error = current_error\n",
        "\n",
        "    # ログの出力\n",
        "    count += 1\n",
        "    log = '{}回目: theta = {}, 差分 = {:.4f}'\n",
        "    print(log.format(count, theta, diff))\n",
        "\n",
        "# プロットして確認\n",
        "x = np.linspace(-3, 3, 100)\n",
        "plt.plot(train_z, train_y, 'o')\n",
        "plt.plot(x, f(to_matrix(x)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zRYZxFQ1tydY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regularization　～正則化を適用しない実装、適用した実装\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 真の関数\n",
        "def g(x):\n",
        "    return 0.1 * (x ** 3 + x ** 2 + x)\n",
        "\n",
        "# 真の関数にノイズを加えた学習データを適当な数だけ用意する\n",
        "train_x = np.linspace(-2, 2, 8)\n",
        "train_y = g(train_x) + np.random.randn(train_x.size) * 0.05\n",
        "\n",
        "# 標準化\n",
        "mu = train_x.mean()\n",
        "sigma = train_x.std()\n",
        "def standardize(x):\n",
        "    return (x - mu) / sigma\n",
        "\n",
        "train_z = standardize(train_x)\n",
        "\n",
        "# 学習データの行列を作る\n",
        "def to_matrix(x):\n",
        "    return np.vstack([\n",
        "        np.ones(x.size),\n",
        "        x,\n",
        "        x ** 2,\n",
        "        x ** 3,\n",
        "        x ** 4,\n",
        "        x ** 5,\n",
        "        x ** 6,\n",
        "        x ** 7,\n",
        "        x ** 8,\n",
        "        x ** 9,\n",
        "        x ** 10\n",
        "    ]).T\n",
        "\n",
        "X = to_matrix(train_z)\n",
        "\n",
        "# パラメータの初期化\n",
        "theta = np.random.randn(X.shape[1])\n",
        "\n",
        "# 予測関数\n",
        "def f(x):\n",
        "    return np.dot(x, theta)\n",
        "\n",
        "# 目的関数\n",
        "def E(x, y):\n",
        "    return 0.5 * np.sum((y - f(x)) ** 2)\n",
        "\n",
        "# 正則化定数\n",
        "LAMBDA = 0.5\n",
        "\n",
        "# 学習率\n",
        "ETA = 1e-4\n",
        "\n",
        "# 誤差\n",
        "diff = 1\n",
        "\n",
        "# 正則化を適用せずに学習を繰り返す\n",
        "error = E(X, train_y)\n",
        "while diff > 1e-6:\n",
        "    theta = theta - ETA * (np.dot(f(X) - train_y, X))\n",
        "\n",
        "    current_error = E(X, train_y)\n",
        "    diff = error - current_error\n",
        "    error = current_error\n",
        "\n",
        "theta1 = theta\n",
        "\n",
        "# 正則化を適用して学習を繰り返す\n",
        "theta = np.random.randn(X.shape[1])\n",
        "diff = 1\n",
        "error = E(X, train_y)\n",
        "while diff > 1e-6:\n",
        "    reg_term = LAMBDA * np.hstack([0, theta[1:]])\n",
        "    theta = theta - ETA * (np.dot(f(X) - train_y, X) + reg_term)\n",
        "\n",
        "    current_error = E(X, train_y)\n",
        "    diff = error - current_error\n",
        "    error = current_error\n",
        "\n",
        "theta2 = theta\n",
        "\n",
        "# プロットして確認\n",
        "plt.plot(train_z, train_y, 'o')\n",
        "z = standardize(np.linspace(-2, 2, 100))\n",
        "theta = theta1 # 正則化なし\n",
        "plt.plot(z, f(to_matrix(z)), linestyle='dashed')\n",
        "theta = theta2 # 正則化あり\n",
        "plt.plot(z, f(to_matrix(z)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ncuUqOYyt89h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}